import asyncio
from pathlib import Path
import requests
import feedparser

from telegram import send_message
from diff import load_state, save_state, get_new_entries, update_state

FEEDS_FILE = Path("publisher/feeds.txt")
STATE_FILE = Path("publisher/state.json")

MAX_CONCURRENCY = 5
TIMEOUT = 15

HEADERS = {
    "User-Agent": (
        "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) "
        "AppleWebKit/537.36 (KHTML, like Gecko) "
        "Chrome/125.0.0.0 Safari/537.36"
    )
}


def fetch_blocking(url: str) -> str:
    """–°–∏–Ω—Ö—Ä–æ–Ω–Ω–∞—è –∑–∞–≥—Ä—É–∑–∫–∞ RSS (–±—É–¥–µ—Ç –≤—ã–∑–≤–∞–Ω–∞ —á–µ—Ä–µ–∑ asyncio.to_thread)."""
    resp = requests.get(url, timeout=TIMEOUT, headers=HEADERS)
    resp.raise_for_status()
    return resp.text


async def fetch_rss(url: str) -> list:
    """–ê—Å–∏–Ω—Ö—Ä–æ–Ω–Ω–∞—è –∑–∞–≥—Ä—É–∑–∫–∞ RSS —á–µ—Ä–µ–∑ –ø–æ—Ç–æ–∫."""
    try:
        xml_text = await asyncio.to_thread(fetch_blocking, url)
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ {url}: {e}")
        return []

    parsed = feedparser.parse(xml_text)

    entries = []
    for item in parsed.entries:
        entry_id = item.get("id") or item.get("link")
        if not entry_id:
            continue

        entries.append({
            "id": entry_id,
            "title": item.get("title", ""),
            "link": item.get("link", ""),
            "summary": item.get("summary", "")
        })

    return entries


def format_entry(entry: dict) -> str:
    """–§–æ—Ä–º–∏—Ä—É–µ—Ç —Ç–µ–∫—Å—Ç —Å–æ–æ–±—â–µ–Ω–∏—è."""
    title = entry["title"].strip()
    link = entry["link"].strip()
    summary = entry.get("summary", "").strip()

    if summary:
        return f"{title}\n{summary}\n{link}"
    return f"{title}\n{link}"


async def process_feed(url: str, state: dict, sem: asyncio.Semaphore):
    """–ó–∞–≥—Ä—É–∂–∞–µ—Ç RSS, –∏—â–µ—Ç –Ω–æ–≤—ã–µ –∑–∞–ø–∏—Å–∏, –æ—Ç–ø—Ä–∞–≤–ª—è–µ—Ç –∏—Ö –∏ –æ–±–Ω–æ–≤–ª—è–µ—Ç state."""

    async with sem:
        entries = await fetch_rss(url)

    if not entries:
        return

    # –ù–∞–π—Ç–∏ –Ω–æ–≤—ã–µ –∑–∞–ø–∏—Å–∏ —á–µ—Ä–µ–∑ diff.py
    new_entries = get_new_entries(url, entries, state)

    if not new_entries:
        print(f"‚Äî –ù–µ—Ç –Ω–æ–≤—ã—Ö –∑–∞–ø–∏—Å–µ–π: {url}")
        # –ù–æ state –≤—Å—ë —Ä–∞–≤–Ω–æ –æ–±–Ω–æ–≤–ª—è–µ–º –Ω–∞ —Å–∞–º—ã–π —Å–≤–µ–∂–∏–π id
        update_state(url, entries, state)
        return

    print(f"‚ú® –ù–æ–≤—ã—Ö –∑–∞–ø–∏—Å–µ–π: {len(new_entries)} ‚Äî {url}")

    # –û—Ç–ø—Ä–∞–≤–ª—è–µ–º –≤ –ø–æ—Ä—è–¥–∫–µ –æ—Ç —Å—Ç–∞—Ä—ã—Ö –∫ –Ω–æ–≤—ã–º
    for entry in reversed(new_entries):
        await asyncio.to_thread(send_message, format_entry(entry))

    # –û–±–Ω–æ–≤–ª—è–µ–º state
    update_state(url, entries, state)


async def main_async():
    feeds = [
        line.strip()
        for line in FEEDS_FILE.read_text().splitlines()
        if line.strip() and not line.startswith("#")
    ]

    print(f"üì° –í—Å–µ–≥–æ RSS-–ª–µ–Ω—Ç: {len(feeds)}")

    state = load_state(STATE_FILE)
    sem = asyncio.Semaphore(MAX_CONCURRENCY)

    tasks = [process_feed(url, state, sem) for url in feeds]
    await asyncio.gather(*tasks)

    save_state(STATE_FILE, state)
    print("‚úÖ –ì–æ—Ç–æ–≤–æ. –í—Å–µ –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è –æ—Ç–ø—Ä–∞–≤–ª–µ–Ω—ã.")


def main():
    asyncio.run(main_async())


if __name__ == "__main__":
    main()
